\section{Overall Algorithm: Putting Ideas 1 and 2 together}
Of course, we will not be able to get such a clean decomposition into a \cckp instance and a collection of locally roundable pieces. Indeed, as we iteratively identify pieces which are either locally roundable or get added to the \cckp instance, the neighborhood structure of the remaining clients and facilities changes, and what may have been originally a locally roundable neighborhood piece may cease to be one subsequently. Our final algorithm then combine the above two ideas in a dynamic manner: we iteratively decompose the clients and facilities into three parts: the first being clients which are supported in the LP solution by locally-roundable neighborhoods, along with the facilities in these neighborhoods, the second is the clients and facilities which are isolated from each other and hence form the \cckp instance, and a third kind of clients (which we refer to as the deleted clients), which are in the proximity of the clients of the first two kinds, and their total demand can be charged to the demands in the first two kinds.
In fact, it is only the second kind of clients and facilities which causes the natural LP to have an unbounded integrality gap, and forces us to use a stronger configuration LP.


\subsection{Configuration LP}
\label{sec:lp}
We assume without loss of generality that we know the $\opt$ value (we can perform binary search over $\opt$ value). By scaling, we can also assume that
 $\opt = 1$. Recall that we can define a bipartite graph $G$ over the set of clients locations and facility locations, and we have an edge between
 two locations if the distance between them is at most 1. We know that there is feasible solution which assigns each client to a location in its neighborhood.
 We now describe the LP relaxation. It will seem that it has exponential number of constraints and variables. But we will worry about solving the LP in polynomial time in a latter section. For the time being, we will assume that a feasible solution consisting of variables
 %The following LP has a feasible solution
 $(y_{ip}, x_{ijp})$  can be found.
 %
 %For the time being, we assume this can be found.
  The variable $y_{ip}$ is 1 if we open a
center of capacity $c_p$ at $i$, 0 otherwise. Similarly, the variable $x_{ijp}$ is 1 if the client at location $j$ is assigned to a center of capacity $c_p$ located at $i$, 0 otherwise. The constraints~\eqref{eq:mkc1-full}-\eqref{eq:mkc3-full} are self explanatory. Constraint~\eqref{eq:mkc1-full} states that each client must be assigned to an open location, constraint~\eqref{eq:mkc2-full} requires that a center of capacity $c_p$ can satisfy a total of at most
$c_p$ demands. Constraint~\eqref{eq:mkc3-full} is simply stating that we can assign a demand to a center of capacity $c_p$ at location $i$ only if we open such a center at $i$. Constraint~\eqref{eq:mkc4-full} captures the fact that we have limited number of centers of each capacity, i.e., for
every $p$, we have only $\sum_{q \geq p} n_q$ centers of capacity $c_p$ or smaller. Note that we could have written a constraint for each capacity type $p$ separately -- for each type $p$, we only have $n_p$ centers of type $p$. However, it is easier to work with aggregate constraints~\eqref{eq:mkc4-full}. It allows us to open an extra center of smaller capacity at the expense of opening one fewer center of higher capacity.

Now we describe constraint~\eqref{eq:proj}.
Let $\Supp$ denote all ordered tuples of the form
$(n_1', \ldots, n_k')$, where $n_p' \leq n_p$ for $p=1, \ldots, k$. Further, for a such a tuple $S$, let $n(S,p)$ denote $n_p'$.
For a tuple  $S \in \Supp$, we abuse notation and let $|S|$ denote $\sum_p n(S,p)$.
 Consider a subset of clients $J$, and the locations $\Gamma(J)$.
 In any feasible solution, the clients in $J$ must be assigned to facilities opened at locations in $\Gamma(J)$ (recall that $\Gamma(J)$ denotes
 the neighbors of $J$ in the bipartite graph $G$).
 Suppose we open $n_p'$ centers of capacity $c_p$ in $\Gamma(J)$ --- let $S$ denote the corresponding tuple
 in $\Supp$. Clearly, the fact that we can open at most one facility at each location implies that (i) $|S| \leq |\Gamma(J)|$ , and (ii) the total capacity in $S$, i.e.,
 $\sum_p n(S,p) \cdot c_p$, is at least the total demand in $J$. Let $\calF_J$ denote the set of all tuples
 in $\Supp$ which satisfy these two properties. For every subset of clients $J$ and $S \in \calF_J$, we have a variable $z_{S,J}$ which is 1 if and only if
 for all $p$, $1 \leq p \leq k$,
 we open $n(S,p)$ facilities of capacity $c_p$ in $\Gamma(J)$. Now the constraints in~\eqref{eq:conflpnew} should be clear -- for each $p$, the total number of
 facilities of size $c_p$ opened in $\Gamma(J)$ must be equal to $\sum_{S \in \calF_j} n(S,p) z_{S,J}$. Note that we have an exponential number of constraints of type~\eqref{eq:proj}, one for each subset $J$. Further, for each such $J$, we have defined an exponential number of variables. We show in Section~\ref{sec:ellipsoid} how to solve such an LP.




\begin{eqnarray}
\sum_{i\in F} \sum_{p\in [P]}  x_{ijp} \geq 1 & \forall j\in C  \label{eq:mkc1-full} \\
\sum_{j\in C} d_j x_{ijp} \leq c_p y_{ip} & \forall i \in F, \forall p\in [P] \label{eq:mkc2-full} \\
x_{ijp} \leq y_{ip} & \forall i\in F, j\in C,\forall p\in [P] \label{eq:mkc3-full}\\
\sum_{q \geq p} y_{iq}   \leq \sum_{q\geq p} n_q & \forall p\in [t] \label{eq:mkc4-full}\\
\nonumber \\
y \in \calP(J) & \forall J\subseteq C \label{eq:proj}
\end{eqnarray}
\noindent
where
\begin{eqnarray}
\calP(J) := & \{ y_{ip}: \exists z_{S,J}\in [0,1] \textrm{ for all } S\in \calF_J \textrm{ such that }  \notag \\
& \forall p\in [P], ~~ \sum_{i\in \Gamma(J)} y_{ip} \geq \sum_{S\in \calF_{J}} z_{S,J}\cdot n(S,p), ~~~~ \textrm{and}~~~~ \sum_{S\in \calF_{J}} z_{S,J} \geq 1 \} \label{eq:conflpnew}
\end{eqnarray}
where $\calF_{J} := \{S\in \Supp: |S| \leq |\Gamma(J)|, \sum_{p\in S} c_p \geq D(J)\}$ and $n(S,p)$ is the number of copies of  $p$ in $S$. \bigskip


\subsection{Solving the LP: Ellipsoid Method}
\label{sec:ellipsoid}
In this section we show how to solve the LP relaxation given in Section~\ref{sec:lp}. The set of constraints specify a feasible region for the set of variables $(x_{ijp}, y_{ip})$, which is convex. Therefore, we can invoke the ellipsoid algorithm to solve the LP as long as we can find a separating hyperplane for any infeasible solution. So let $(x_{ijp}, y_{ip})$ be a tentative solution. Since the  constraints in~\eqref{eq:mkc1-full}-\eqref{eq:mkc3-full} are polynomial in number, we can check feasibility for these constraints easily. Consider a {\em fixed} set  of clients $J$.
We show how to check the constraints~\eqref{eq:proj} for $J$. We re-write the constraints~\eqref{eq:conflpnew} for $J$ below:
\begin{eqnarray*}
\sum_{S \in \calF_J} z_{S,J} & \geq & 1 \\
\sum_{S\in \calF_{J}} z_{S,J}\cdot n(S,p) &\leq  & \sum_{i\in \Gamma(J)} y_{ip}  \ \ \ \forall p \in [P] \\
z_{S,J} & \geq &  0 \ \ \ \forall S \in \calF_J
\end{eqnarray*}

Note that we do not explicitly need to say $z_{S,J} \leq 1$ as existence of a solution to the above constraints also guarantees another solution
which satisfies $z_{S,J} \leq 1$ for all $S \in \calF_J$. Treating $y_{ip}$ values as constants, we know by Farkas' lemma that either there is a feasible solution to
the above constraints, or there is a feasible solution to the following set of constraints (where the variables are $\alpha_p, p \in [P]$),
which we call dual LP:
 \begin{eqnarray}
\sum_{p \in P} \left( \sum_{i \in \Gamma(J)} y_{ip} \right) \cdot  \alpha_p & > & 1 \\
\label{eq:ellipsoid1}
 \sum_{p \in [P]} n(S,p) \cdot \alpha_p & \leq & 1 \ \ \ \forall S \in \calF_J \\
 \label{eq:ellipsoid2}
\alpha_p & \geq & 0
\end{eqnarray}

Now, if there is no feasible solution to the above set of constraints, then we know that the solution $y \in \calP(J)$. Otherwise, if there is a
feasible solution, then the first constraint  gives a separating hyperplane. Thus, it is enough to find a solution to the above set of constraints, or
declare that it is infeasible. We check the above constraints again by the ellipsoid algorithm. Thus, given $\alpha_p$ values we need to check that
for all $S \in \calF_J$, $\sum_{p \in [P]} n(S,p) \cdot \alpha_p \leq 1$. We can restate the following problem as follows:

Amit: need to write this part.


%
%Solving the above dual is same as finding the maximum value of
%$\sum_{p \in P} \left( \sum_{i \in \Gamma(J)} y_{ip} \right) \cdot  \alpha_p $  subject to constraints~\eqref{eq:ellipsoid1}-\eqref{eq:ellipsoid2}.
%This can be solved by another round of ellipsoid algorithm. At this time, a separation oracle will require us to solve the following problem -- given
%non-negative values $\alpha_p, p \in [P]$, find the maximum, over all $S \in \calF_J$, of $\sum_{p \in [P]} n(S,p) \cdot \alpha_p$. One can solve this by a standard
%dynamic programming algorithm. In the DP, we can maintain a table $T[p,C,q]$ which will store the maximum value of $\sum_{p'=1}^p n(S,p') \cdot
%\alpha_{p'}$ over all $S$ satisfying the following constraints~: (i) $\sum_{p'=1}^p n(S,p') = q$, (ii) $\sum_{p'=1}^p n(S,p') \cdot c_{p'} = C$,
%(iii) $n(S,p') \leq n_{p'}$ for $p = 1, \ldots p'$.
%It is to easy to see that we can fill in the DP table in pseudo-polynomial time. In order to make it run in polynomial time, we need to use standard
%rounding techniques, but we then we lose $(1+\varepsilon)$ factor in approximation ratio for a small parameter  $\varepsilon$ -- we can make
%$\varepsilon$ to be $1/poly(n)$, where $n$ is the number of vertices in $G$.
%
%This implies that we will be able to check the dual LP up to this factor only. Translating this statement back to the primal LP (i.e., constraints given
%by~\eqref{eq:proj}), we see that in polynomial time, we can show one of the following facts: (i) There is a separating hyperplane between $y$
%and $\calP(J)$, or (ii) the solution $y$ satisfied $\calP(J)$ {\em approximately}, i.e., there exist $z_{S, J}$ variables such that
%$\sum_{S \in \calS(J)} z_{S,J} \geq 1$ and $\sum_{i \in \Gamma(J)} y_{ip} \geq (1 - \varepsilon) \cdot \sum_{S \in \calF_J} z_{S,J} \cdot n(S,p)$
%for all $p \in [P]$.
%
%So far we have discussed the case of single set $J$ only. Now we use the observation that given a tentative solution $(x_{ijp}, y_{ip})$, our algorithm
%requires the constraints~\eqref{eq:proj} to hold for a linear (in terms of vertices in $G$) number of subsets $J$ only -- say $J_1, \ldots, J_\ell$. Thus,
%we can apply the above steps for $J = J_1, \ldots J_\ell$. We get the following result:
%\begin{theorem}
%\label{thm:ellipsoid}
%Given a tentative solution $(x, y)$, and polynomial number of subsets $J_1, \ldots, J_\ell$, we can decide between the following two cases in polynomial time:
%\begin{itemize}
%\item The solution is infeasible and and we can find a separating hyperplane.
%\item The solution satisfies the constraints $\calP(J)$ for $J=J_1, \ldots, J_\ell$ up to $(1-\varepsilon)$ factor as mentioned above, where
%$\varepsilon$ is a polynomially small parameter.
%\end{itemize}
%\end{theorem}
%It follows that as far as our rounding algorithm is concerned, we can assume that we have a solution to the LP (assuming the $(1- \varepsilon)$ factor).
%
%

